# ContextEncoder
An implementation of [context encoder](http://people.eecs.berkeley.edu/~pathak/context_encoder/) by Deepak Pathak with changes in original model intended to improve results.
## Inpainting Results
### After remodelling discriminator
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/122_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/125_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/126_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/127_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/128_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/131_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/133_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/141_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/143_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/149_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/152_output.jpg)
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/154_output.jpg)

### DEMO
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/9.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/25.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/34.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/89.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/101.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/141.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/142.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/143.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/146.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/174.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/186.gif))
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/200.gif))

### After further improvements
Ground Truth | Input | Output | Ground Truth | Input | Output 
------|--------------|--------|-------|--------------|--------
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/9_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/9_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/9_output.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/25_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/25_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/25_output.jpg) |
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/34_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/34_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/34_output.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/89_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/89_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/89_output.jpg) |
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/101_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/101_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/101_output.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/141_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/141_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/141_output.jpg) |
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/142_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/142_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/142_output.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/143_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/143_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/143_output.jpg) |
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/146_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/146_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/146_output.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/174_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/174_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/174_output.jpg) |
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/186_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/186_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/186_output.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/200_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/200_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/200_output.jpg) |
![](https://github.com/afrozalm/ContextEncoder/blob/master/results/496_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/496_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/496_output.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/490_groundTruth.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/490_input.jpg) |![](https://github.com/afrozalm/ContextEncoder/blob/master/results/490_output.jpg) |
